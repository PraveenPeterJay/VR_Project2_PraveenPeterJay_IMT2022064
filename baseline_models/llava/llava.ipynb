{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11780383,"sourceType":"datasetVersion","datasetId":7395946},{"sourceId":11780569,"sourceType":"datasetVersion","datasetId":7396089}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install bert-score rouge-score tqdm nltk\n# Download NLTK data for BLEU\nnltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T10:01:00.409483Z","iopub.execute_input":"2025-05-16T10:01:00.410312Z","iopub.status.idle":"2025-05-16T10:01:03.868973Z","shell.execute_reply.started":"2025-05-16T10:01:00.410280Z","shell.execute_reply":"2025-05-16T10:01:03.867881Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: bert-score in /usr/local/lib/python3.11/dist-packages (0.3.13)\nRequirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.5.1+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.51.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (24.2)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.30.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert-score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert-score) (2024.2.0)\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow warnings\n\nimport pandas as pd\nimport torch\nfrom transformers import AutoProcessor, LlavaForConditionalGeneration\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nfrom bert_score import score as bert_score\nfrom rouge_score import rouge_scorer\nfrom nltk.translate.bleu_score import sentence_bleu\nimport numpy as np\nfrom tqdm import tqdm\nimport nltk\nimport gc\n# Suppress all warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Suppress specific logging\nimport logging\nlogging.getLogger(\"transformers\").setLevel(logging.ERROR)\nlogging.getLogger(\"torch\").setLevel(logging.ERROR)\nlogging.getLogger(\"PIL\").setLevel(logging.ERROR)\nlogging.getLogger(\"nltk\").setLevel(logging.ERROR)\nlogging.getLogger(\"sklearn\").setLevel(logging.ERROR)\n\n# Define paths\nDATASET_PATH = \"/kaggle/input/dataset/Complete_vqa(in).csv\"\nIMAGE_BASE_PATH = \"/kaggle/input/imagedataset/small\"\nOUTPUT_LOG_5 = \"/kaggle/working/llava_baseline_5.csv\"\nOUTPUT_LOG_10 = \"/kaggle/working/llava_baseline_10.csv\"\n\n# Load dataset\nprint(\"Loading VQA dataset...\")\nvqa_df = pd.read_csv(DATASET_PATH)\n\n# Initialize metrics tracking\nmetrics_columns = ['image_path', 'question', 'answer', 'prediction', 'correct', \n                   'meteor', 'f1', 'accuracy', 'bertscore_precision', \n                   'bertscore_recall', 'bertscore_f1', 'partscore', 'rouge_1_f1']\n\n# Function to load image\ndef load_image(image_path):\n    full_path = os.path.join(IMAGE_BASE_PATH, image_path)\n    if not os.path.exists(full_path):\n        raise FileNotFoundError(f\"Image not found: {full_path}\")\n    return Image.open(full_path).convert(\"RGB\")\n\n# Function to predict answer with memory management\ndef predict_answer(image, question):\n    formatted_question = f\"<image> Question: {question} Answer:\"\n    \n    # Move inputs to CUDA explicitly\n    inputs = processor(text=formatted_question, images=[image], return_tensors=\"pt\", padding=True)\n    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n    \n    with torch.no_grad():\n        output = model.generate(**inputs, max_new_tokens=5)\n    \n    predicted_answer = processor.decode(output[0], skip_special_tokens=True).strip().lower()\n    \n    # Clear CUDA cache explicitly\n    del inputs, output\n    torch.cuda.empty_cache()\n    \n    words = predicted_answer.split()\n    if words:\n        last_word = words[-1]\n        last_word = last_word.rstrip('.')  # Remove trailing punctuation\n        return last_word\n    return \"\"\n\ndef run_evaluation(sample_percentage, output_file):\n    # Sample the dataset\n    sample_size = int(len(vqa_df) * (sample_percentage / 100))\n    print(f\"Running evaluation on {sample_percentage}% of dataset ({sample_size} samples)...\")\n    \n    sampled_df = vqa_df.sample(n=sample_size, random_state=42)\n    questions = sampled_df['question'].tolist()\n    original_answers = sampled_df['answer'].tolist()\n    ground_truth_answers = [str(ans).lower() for ans in original_answers]\n    image_paths = sampled_df['image_path'].tolist()\n    \n    # Initialize results dataframe\n    results_df = pd.DataFrame(columns=metrics_columns)\n    \n    # Process in batches to manage memory\n    batch_size = 1  # Process one image at a time\n    \n    for idx in tqdm(range(len(image_paths)), desc=f\"Processing {sample_percentage}%\"):\n        try:\n            image_path = image_paths[idx]\n            question = questions[idx]\n            gt_answer = ground_truth_answers[idx]\n            \n            # Load image and predict\n            image = load_image(image_path)\n            pred_answer = predict_answer(image, question)\n            \n            # Calculate individual metrics\n            correct = pred_answer.lower() == gt_answer.lower()\n            \n            # METEOR score (placeholder)\n            meteor = 0.5 if correct else 0\n            \n            # F1 score (placeholder)\n            f1 = 1 if correct else 0\n            \n            # Accuracy (binary)\n            acc = 1 if correct else 0\n            \n            # BERTScore for this sample\n            p_bert, r_bert, f1_bert = bert_score([pred_answer], [gt_answer], lang=\"en\", verbose=False)\n            \n            # ROUGE score for this sample\n            scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n            rouge = scorer.score(gt_answer, pred_answer)['rouge1'].fmeasure\n            \n            # BLEU score (partscore in your example)\n            try:\n                bleu = sentence_bleu([gt_answer.split()], pred_answer.split())\n            except:\n                bleu = 0\n                \n            # Store results\n            row = {\n                'image_path': image_path,\n                'question': question,\n                'answer': gt_answer,\n                'prediction': pred_answer,\n                'correct': str(correct),  # Convert to string 'True'/'False'\n                'meteor': meteor,\n                'f1': f1,\n                'accuracy': acc,\n                'bertscore_precision': p_bert.item(),\n                'bertscore_recall': r_bert.item(),\n                'bertscore_f1': f1_bert.item(),\n                'partscore': bleu,\n                'rouge_1_f1': rouge\n            }\n            \n            # Append to results dataframe\n            results_df = pd.concat([results_df, pd.DataFrame([row])], ignore_index=True)\n            \n            # Force garbage collection\n            if idx % 5 == 0:\n                gc.collect()\n                torch.cuda.empty_cache()\n                \n        except Exception as e:\n            print(f\"Error at sample {idx+1}: {e}\")\n            \n            # Add empty row on error\n            row = {col: \"\" for col in metrics_columns}\n            row.update({\n                'image_path': image_paths[idx],\n                'question': questions[idx],\n                'answer': ground_truth_answers[idx],\n                'prediction': \"\",\n                'correct': \"False\"\n            })\n            results_df = pd.concat([results_df, pd.DataFrame([row])], ignore_index=True)\n            \n            # Try to recover memory on error\n            gc.collect()\n            torch.cuda.empty_cache()\n    \n    # Calculate overall metrics for reporting\n    overall_accuracy = accuracy_score(\n        results_df['correct'].map({'True': True, 'False': False}), \n        [True] * len(results_df)\n    )\n    overall_bertscore_f1 = results_df['bertscore_f1'].mean()\n    overall_rouge = results_df['rouge_1_f1'].mean()\n    overall_bleu = results_df['partscore'].mean()\n    \n    # Save results to CSV\n    results_df.to_csv(output_file, index=False)\n    print(f\"Results for {sample_percentage}% saved to {output_file}\")\n    \n    # Summary\n    print(f\"\\nEvaluation Summary for {sample_percentage}%:\")\n    print(f\"- Accuracy: {overall_accuracy:.4f}\")\n    print(f\"- BERTScore F1: {overall_bertscore_f1:.4f}\")\n    print(f\"- ROUGE-1 F1: {overall_rouge:.4f}\")\n    print(f\"- BLEU: {overall_bleu:.4f}\")\n\n# Initialize LLaVA model and processor\nprint(\"Loading LLaVA model and processor...\")\nmodel_id = \"llava-hf/llava-1.5-7b-hf\"\nprocessor = AutoProcessor.from_pretrained(model_id)\nmodel = LlavaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")\nmodel.eval()\n\n# Run evaluations\ntry:\n    # Run for 5% first\n    run_evaluation(5, OUTPUT_LOG_5)\n    \n    # Clear memory before next run\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    # Run for 10%\n    run_evaluation(10, OUTPUT_LOG_10)\n    \nexcept Exception as e:\n    print(f\"Fatal error: {e}\")\nfinally:\n    # Clean up\n    del model, processor\n    gc.collect()\n    torch.cuda.empty_cache()\n    print(\"Evaluation completed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T06:28:38.177583Z","iopub.execute_input":"2025-05-16T06:28:38.178270Z","iopub.status.idle":"2025-05-16T09:55:19.036848Z","shell.execute_reply.started":"2025-05-16T06:28:38.178242Z","shell.execute_reply":"2025-05-16T09:55:19.036160Z"}},"outputs":[{"name":"stdout","text":"Loading VQA dataset...\nLoading LLaVA model and processor...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f102eed12c0e4cb39e0a872b594c475e"}},"metadata":{}},{"name":"stdout","text":"Running evaluation on 5% of dataset (2274 samples)...\n","output_type":"stream"},{"name":"stderr","text":"Processing 5%: 100%|██████████| 2274/2274 [1:08:56<00:00,  1.82s/it]\n","output_type":"stream"},{"name":"stdout","text":"Results for 5% saved to /kaggle/working/llava_baseline_5.csv\n\nEvaluation Summary for 5%:\n- Accuracy: 0.5123\n- BERTScore F1: 0.9826\n- ROUGE-1 F1: 0.5263\n- BLEU: 0.0000\nRunning evaluation on 10% of dataset (4548 samples)...\n","output_type":"stream"},{"name":"stderr","text":"Processing 10%: 100%|██████████| 4548/4548 [2:17:02<00:00,  1.81s/it]  \n","output_type":"stream"},{"name":"stdout","text":"Results for 10% saved to /kaggle/working/llava_baseline_10.csv\n\nEvaluation Summary for 10%:\n- Accuracy: 0.5070\n- BERTScore F1: 0.9822\n- ROUGE-1 F1: 0.5225\n- BLEU: 0.0000\nEvaluation completed.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}